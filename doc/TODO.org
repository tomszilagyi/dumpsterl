Dumpsterl

The purpose of Dumpsterl is to provide a powerful, extensible and
user-friendly framework for data exploration in NoSQL environments.

* Features

Stuff that definitely needs treatment before the initial public release

** General
*** TODO documentation
- EDoc should be generated and contain API documentation
- AsciiDoc should be generated and contain user guide

*** TODO reorg modules
  - ds -> ds_core or ds_spec or ds_tree
  - ds should be an interface module and the only module the user has
    to manually call functions in, eg. ds:shell(), ds:gui(), etc.

*** TODO testing
**** TODO test data model

An exemplary data model should be devised and a data generator written
that randomly generates instances of that data, for testing purposes.

**** TODO test the terminal support on ansi, cygwin, Eterm, etc.

see /lib/terminfo/* for inspiration

**** TODO test on Windows and Mac (if possible)
**** DONE foreach_otp ./do_test.sh

A script to exercise all the tests with all Erlang versions of
interest (~R14 to latest).

** Probe: data acquisition phase
*** DONE statistical sampling
- don't add the same value multiple times to samples, to maximize the
  number of unique values shown. Instead, for each collected value,
  maintain per-value stats to show how it is distributed across the
  population.
*** DONE cardinality estimation
*** DONE tag each data with arbitrary attributes
What Dumpsterl itself uses for display purposes:
 - timestamp (when was this data created)
 - key (to read back the whole record)
*** DONE support for records
- read schema.DAT to learn about mnesia schema (table attributes)
- go through loaded modules to gather record attributes in loaded code

- store field attributes automatically, when first encountering
  a record type
- the field attributes information for records is stored in Ext
- the initial attributes gatherin phase can rely on several sources:
  - code: record attribute definitions in loaded beam/source
    files, read once at the beginning, see rec_attrs in ds_opts.
    The best way to get all attributes, but requires the probe to be
    run in a node with the production code also loaded.
  - disk_log -> read schema.DAT
    Supported in case a bare Erlang node runs the probe. Will not
    find attributes to records that are not the basis of any table
    (embedded in table fields).
  - mnesia -> mnesia:table_info(T, attributes)
    Not supported: if dumpsterl is run on a system where
    mnesia is up and running, the code accessing the tables is
    also loaded, so we can get the same info (and more) from the
    beam/source attributes.
    But maybe, MAYBE it would be worth adding anyway?

*** DONE dets tables support

The opening and closing of a dets table should be done as part of
running the spec function in ds_drv, similar to disk_log files.
The table parameter could take the filename.

Is it possible to have a keypos other than 2? If yes, it needs to be a
(perhaps optional) parameter to the spec function.

*** DONE support 'result' flag
  Default false. When set to true, return the result of the spec to
  the caller (as is now). The goal is to reduce clutter in the
  terminal, as most users will dump the spec to file for opening it in
  the gui.

  NB. this has been dropped. The probe api has been changed so that
  it is possible to run the spec() function directly, which returns
  the spec tree. It is also possible to run start() manually, which
  - yields a pid and monitor ref, making it possible to manually stop
    the probe before the limit is reached;
  - does not return the spec as a return value, only dumps (if enabled).
*** TODO support 'keep' flag
- sampler: provide attribute 'keep' to signify that a particular
  piece of data satisfies certain criteria to be 'interesting'.
  This attribute would ensure that the data is kept stored
  regardless of sampling allowances. Implement with a dedicated
  sampler initialized with capacity 'infinity'.
*** DONE parallelize
  send data to N trees in round-robin fashion, then
  - join results regularly for each chunk, OR
  - dump each separately (e.g. ds.bin.k) and join k=0..N at the end
    (N > number of processors) OR
  - do interim dumps from one process only (the master),
    join with results from other threads and dump that as final
    result.

  The last option above has been implemented.

*** DONE probe command shell to control the probe driver
 - print progress updates using vt100 rewrite-last-line technique
 - line oriented command syntax after ds> prompt to support:
   - setting and viewing options before a run
   - run, stop, refine settings, run, ...
 - show last dump size as part of progress status line
*** TODO probe command shell: additional features/ideas
 - when setting a table for disk_log and dets, check if file exists
 - help listing/browsing available tables
 - show attributes to help choosing the right spec
 - support syntax to enter complex field specs
*** DONE save probe metadata in spec dump
- when dumping, also dump metadata (apart from the spec itself):
  - the progress information (total items traversed so far). May be
    more than the count in the Stats of 'T' in case of skipped items.
  - options used for the run
  - wall clock of start and end
- the data can be put into Ext of the spec's root node.
** Conversion: between probe and gui
*** DONE compact
  cut intermediary stages of the hierarchy, e.g. if they are all
  integers, get rid of 'T' and 'numeric'. Formally, all nodes with
  only one child should be removed and replaced by the child.
*** DONE join_up
 account each data term only in leaf node, and when assembling the
 tree, derive parent nodes based on the union of children.
*** DONE get the metadata from root node's Ext
** Type system
*** DONE The fundamental semantics of the type hierarchy

Children in the type hierarchy are regarded as either
- alternative subtypes of the current union type;
- the various parameters of the current generic type.

Type parameters are the concept behind the generic types of
tuple, record, list and more (e.g., maps and dict-like types).
For example, the improper_list type has two parameters, the type of
the list items and the type of the tail item. The tuple type
has a parameter for each field position. The map type has a parameter
for each unique key ever seen in any map instance in that position.

The code could be refactored a bit to reflect the above simple
underlying concept.

*** DONE Complete coverage of Erlang types
**** DONE maps

Maps are a generic type. Attributes of a map are the transitive union
set of keys seen in any instance.

Representing a map node in the spec:
- Children contain specs for each attribute;
- Ext contains the list of attributes, that is:
  [Key1, Key2, ...]
  corresponding to the spec list in Children.

We don't want the map size to be part of its spec, because map
instances occurring in the same position could easily contain optional
keys not found in other instances. We want to keep fragmentation of
the spec to a minimum.  Differing counts of key occurrences will be
reflected by the counters of each child spec, reflected by the Count
column of the type parameter listing in the gui.

*** TODO polymorphism of generic types

PROBLEM: term is a list of bytes, OR a list of tuples, but these are
never mixed within the same list. Currently the resulting spec will
show that the list item type is a union of byte | tuple, but will
not indicate that each individual list is either a list of bytes or a
list of tuples. It would be better(?) if the nonempty_list was
subclassed further for each subset of types encountered.

*** TODO Type labeling / shorthand descriptions / reductions

The raw end result of the probing stage will reflect the core Erlang
types (enriched with record information) found in the data.

Before displaying it, we want to reduce the tree with a set of rules
to yield a more compact representation and push type information
upwards to the extent practical. All the detail and sub-levels should
stay available.

This practically means labelling abstract types with shorthand
descriptions derived from their inferior types.

Examples:

non_empty_list -> byte
  becomes:
[byte] -> byte

non_empty_list -> byte
               -> tuple,2 -> atom
                          -> pos_integer -> char
  becomes:
[byte | {atom, pos_integer}] -> byte
                             -> {atom, pos_integer} -> atom
                                                    -> pos_integer -> char

For the above to work, some rules are needed for generating a textual
representation of types.

It is also possible to discover complex types based on certain
patterns of their subtrees, e.g.:
 - proplist()
 - iodata(), iolist()

Examples:

non_empty_list -> char
  becomes:
string -> char

non_empty_list -> atom
               -> tuple,2 -> atom
                          -> 'T' -> ...
  becomes:
proplist -> atom
         -> 'T' -> ...

For this, some rules are needed to rename nodes matching a certain
type signature (self + inferior type nodes)

A declarative, user-editable syntax would be nice.
That way, the user could add their specific type notations and
see them in action.

** GUI: spec browser/explorer
*** DONE GUI browser concept
- two panes: left for navigation, right for details
- navigation pane:
  - type hierarchy stack
    see where the view is located; clicking on any parent
    jumps up to that level
    eg. T -> tuple -> {record, {kcase, 21}}
  - subtype / element list
    shows the list of subspecs below the currently selected one;
    clicking on any of them navigates the view down to that level

    in case of complex structures, this shows a list of these specs,
    allowing the user to click on one of them. The view is then
    directed to the toplevel spec of that element, as a further level
    down the hierarchy.
    eg. T -> tuple -> {record, {kcase, 21}} -> element(2) or #kcase.cid

    the transitions may be distinguished by coloring the entry
    in the type hierarchy stack, e.g.
      subtype: light grey;
      field / element / item: light orange

- details pane:
  - statistics visualization panel
  - private data visualization panel

- statistics and private data should expose accessors so the
  gui can be displayed on a modular basis (i.e. knowledge of the
  data structure, and how to display it, should reside in the
  statistics or private data module; gui code should remain generic).

- when showing a type with sub-fields, the columns in the lower tab
  should be Field, Attribute, Type instead of Type, Count (since these
  counts are always all identical to that of the complex type).
  Field is the field number and Attribute is the field name.

*** TODO GUI outstanding tasks
- timeline: implement heuristics for xtics format and interval based
  on data
- histogram:
  - links to set binning on/off, ylog on/off
  - link to show/hide underlying data as a table
*** GUI toolbars
**** at the top of spec window
- show probe metadata
- set timestamp decoder function
**** at the top of report
- enable/disable attribute columns in report
- save/export report page
*** Display probe metadata in GUI
*** Allow setting timestamp decoder function
- manually supply timestamp format function
  e.g. if it turns out the ts is in gregorian seconds, allow
  user to set fun calendar:gregorian_seconds_to_datetime/1.
*** Manage record attributes
- button next to "Type parameters" if record
- button opens "Record attributes" window
- allow choosing another one (the first is used as a default)
- allow manually adding/removing attributes (e.g. if none have been
  collected)
*** TODO additional gui features
- search: allow entering a piece of string, data, etc.
- toolbar: load, save, generate report, exit, etc.
- manually add field information in case it could not be
  gathered automatically
- allow opening and viewing multiple specs perhaps as part
  of a MDI windowing solution (wx: aui)
- allow exporting the lists of data (e.g. samples of a node)
  to external files
  - list of terms suitable to read with file:consult/1
  - binary via term_to_binary
  - csv (maybe limited to cases where data is simple eg. integers?)
- say 'all' instead of count figure when same as super-type
  (this is not always meaningful, only for leaf nodes that are not
  generic types)
- also show percentage in the above cases (where it clearly entails
  a subset share of a total set)

*** TODO support viewing data in different formats
  e.g. if we suspect that an integer contains bit flags,
  it is helpful to be able to switch to a hex/bin view
  and maybe even give names to different bits.


* Ideas

More tentative / needs research / not a well defined feature to work on

** how does the probe get smoothly loaded into a node?
- it is generally possible to include the application in the host Erlang
  system, but that is not always desirable (wx, etc).
- a user-friendly mechanism to load only the probe modules would be
  nice.
- support compiling the probe only (without wx present)
- support compiling without maps (on old Erlang systems)
** 'decision tree compiler' for quick computation of values' subtypes
 Allow the user to express the type hierarchy in a more succinct way
 and generate the types categorization code out of that.
** more efficient in-memory representation of tree, for faster updates
  store all nodes in a flat ets table keyed by class, since they are
  unique; updating a node does not involve rebuilding the whole data
  structure
  needed? (perf perspective)
  doable? (cross type domains with generic types)

